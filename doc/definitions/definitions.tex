\chapter{Wprowadzenie}

W celu dobrego przedstawienia problemów i algorytmów będących tematem pracy, niezbędne jest przytoczenie podstawowych pojęć oraz zagadnień odnoszących się NP-zupełności.

Bazowym pojęciem, które w pierwszej kolejności należy przedstawić jest sam termin "problemu". Według definicji w [1] problem abstrakcyjny $Q$ jest relacją dwuargumentową, określoną na zbiorze $I$ egzemplarzy problemu oraz zbiorze $S$ rozwiązań problemu. Egzemplarzem jest struktura matematyczna, natomiast podzbiór jej elementów składowych jest rozwiązaniem. Przenosząc to na przykład dla problemu MAXIMUM-INDEPENDET-EDGE-SET (czyli znalezienia maksymalnego skojarzenia) egzemplarzem jest graf $G$ złożony ze zbioru wierzchołków $V$ oraz krawędzi $E$. Zatem maksymalny zbiór krawędzi niemających wspólnych wierzchołków jest rozwiązaniem tego problemu. Skoro problem jest relacją, a nie funkcją, możliwa jest sytuacja, że dla jednego egzemplarza może istnieć wiele rozwiązań.

W przypadku poruszania się w obrębie teorii NP-zupełności takie definiowanie problemu jest zbyt ogólne, dlatego najlepiej jest ograniczyć się do problemów decyzyjnych. W tej formie znana jest instancja problemu oraz wynik będący odpowiedzią. W przypadku INDEPENDET-EDGE-SET egzemplarz ma postać $i = <G,k>$ , a rozumiany jest następująco: w grafie $G$ istnieje skojarzenie o mocy co najmniej $k$. Rozwiązaniem jest podzbiór zbioru krawędzi $E' \in E$ o mocy co najmniej $k$. Zadanie polega na zweryfikowaniu, czy podany wynik jest rzeczywiście prawdziwy. Nie trudno zauważyć ,że dla tak postawionego problemu zbiór odpowiedzi w takim przypadku ogranicza się do dwóch wartości prawdy lub fałszu. Pozornie łatwe podejście w celu rozpatrywania problemu nie jest wcale takie proste, gdy dochodzi do jego realizacji.
	
Inną formą podejścia do problemu jest podejście optymalizacyjne. Podobnie jak w problemie decyzyjnym na wstępie otrzymuje się instancję problemu, jednak nie występuje sugerowane rozwiązanie. Głównym zadaniem jest teraz znalezienie najlepszego wyniku, w zależności czy zbiór wynikowy ma się minimalizować ( w celu zmniejszania pewnych kosztów) czy też chodzi o maksymalizowanie ( w celu zwiększenia pewnych zysków). Odpowiedzą tak sformułowanemu problemowi będzie moc zbioru wynikowego, czasami również elementy tego zbioru. Mimo, iż optymalizacyjne podejścia wydają się przy realizacji trudniejsze, można je łatwo zastąpić formą decyzyjną w bardzo prosty sposób. Należy obrać początkową trywialną wartość, a następnie zmieniać ją o jednostkową wartość do momentu, aż przestanie istnieć rozwiązanie dla danej wartości. W przypadku minimalizacji za trywialną wartość obieramy maksymalną wartość dla zbioru, którą później dekrementujemy. Natomiast dla maksymalizacji trywialną wartością startową jest zero, które zwiększamy, aż do momentu w którym przestanie istnieć rozwiązanie.

Większa część problemów należy do klasy złożoności P, dlatego rzadko podejmuje się problemy wybiegające poza tę klasę. Problemy będące tematem tej pracy wybiegają dalej i dotyczą sławnej hipotezy: "czy P $\ne$ NP", dlatego obszar który podejmuje praca odnosi się do klas problemów P, NP i NPC.

Najbardziej powszechna klasa P zawiera ten zbiór problemów, dla których istnieje algorytm znajdujący rozwiązanie w czasie wielomianowym. Czas działania algorytmu oznacza się jako funkcję $f$ ,która będzie działać ze zbioru oznaczającego rozmiar danych o ustalonym kodowaniu na zbiór odpowiadający liczbie operacji elementarnych potrzebnych do zakończenia działania algorytmu. Przy tak określonej funkcji, jeśli można ją ograniczyć z góry przez dowolną funkcję wielomianową $O(nk)$, to wtedy problem należy do klasy złożoności P.

O ile P $\ne$ NP, to klasa NP zawiera te problemy, które są "weryfikowalne" w czasie wielomianowym. Przez słowo "weryfikowalne" rozumie się, że istnieje takie świadectwo pozytywne (zwane inaczej dowodem), dzięki któremu można sprawdzić, czy otrzymane rozwiązanie jest poprawne.
Klasa P $\subseteq$ NP. Zatem, skoro mozna rozwiązać problem w czasie wielomianowym, to tym bardziej można w wielomianowym czasie sprawdzic pozytywnmość świadectwa.

Klasa NPC jest tym, co różni klasę P i NP. W jej skład wchodzą te problemy, które należą do NP a nie należą do P. Nasuwa się pytanie: "Czy w ogóle istnieją takie problemy z klasy NP, których nie można rozwiązać w czasie wielomianowym?". Na obecny stan rzeczy odpowiedz brzmi: nie wiadomo. W czasie powstawania pracy nikt dotąd nie udowodnił, że wszystkie problemy $Q\in$ NP są rozwiązywalne w czasie wielomianowym, ani też nie pokazał, że istnieje taki problem z klasy NPC, który nie jest rozwiązany w czasie wielomianowym. Tematem tej pracy są właśnie te problemy o których wiadomo, że są weryfikowalne w czasie wielomianowym, a nie są rozwiązywalne w czasie wielomianowym.

\input{definitions/class_set.tex}

Szczególną własnością problemów NPC jest fakt,iż jeśli choć jeden problem znajdzie się w klasie P, to wszystkie problemy z klasy NPC będą należały do klasy P. Pokazuje to, że jeśli uda się znaleźć algorytm wielomianowy rozwiązujący jakikolwiek problem z klasy NPC to oznaczałoby, że P $=$ NP. Związanie ze sobą tych wszystkich problemów NPC zawdzięcza się redukcji wielomianowej. Polega ona na tym, że rozwiązanie pewnego problemu można sprowadzić do rozwiązania innego. Odbywa się to za pośrednictwem algorytmu redukcji, który jest w stanie przeprowadzić każdą instancję problemu $A$ do postaci instancji problemu $B$ w czasie wielomianowym. Aby to zobrazować, można posłużyć się trywialnym przykładem, w którym problem $Q$ obliczenia długości wektora w $\mathbb{R}^{2}$ zredukuje się do problemu $Q'$ obliczenia długości wektora w $\mathbb{R}^{3}$. Mając tak zdefiniowane problemy potrzebny jest jeszcze algorytm redukcji. Nasz algorytm będzie rozszerzał wektor o trzecią pozycję i wpisywał w to miejsce $0$. Teraz każdy wektor z $\mathbb{R}^{2}$ możemy przedstawić w $\mathbb{R}^{3}$, a następnie obliczyć jego długość. Widać, że długość wektora $[x1,x2,0]$ odpowiada długości wektora $[x1,x2]$. Pokazuje to, że problem $Q$ można zredukować do problemu $Q'$.

Mimo, iż tak wiele wiadomo o problemach NP-zupełnych, to nadal sprawiają one wyzwanie. O ile algorytmy o złożoności większej od wielomianowej potrafią znaleźć optymalne rozwiązanie, o tyle należy mieć pewność, że dane będą z odpowiednio wąskiego zakresu. Jeśli jednak zakres danych jest zbyt duży, pozostaje jedynie heurystyczne poszukiwanie wyniku dla mocno sprecyzowanego problemu lub zadowolenie się wynikiem zbliżonym do optymalnego w oparciu o algorytm aproksymacyjny. W przypadku heurystycznego podejścia nie można za wiele powiedzieć, gdyż wszystko zależy od indywidualnej potrzeby, o którą musi zadbać algorytm  oraz improwizacji, na którą można sobie pozwolić.

Obecnie najbardziej popularną metodą jest wykorzystanie algorytmów aproksymacyjnych ze względu na ich wielomianową złożoność. Jakość takiego algorytmu zależy od znalezionego rozwiązania $C$ względem rozwiązania optymalnego $C^{*}$. Współczynnik aproksymacji $1 \leq \rho(n)$ jest wyznacznikiem jakości i ogranicza z góry stosunek kosztów: $max(\dfrac{C}{C^{*}},\dfrac{C^{*}}{C}) \leq \rho(n)$

Wzór ten uwzględnia przypadek zarówno maksymalizacji, jak i minimalizacji określając ile razy otrzymane rozwiązanie jest gorsze od optymalnego. Dla maksymalizacji mamy $0 \leq C \leq C^{*}$ czyli wartość znalezionego rozwiązania jest nie większa od rozwiązania optymalnego. Natomiast w problemie minimalizacji $0 \leq C^{*} \leq C$ wartość znalezionego rozwiązania jest nie mniejsza od rozwiązania optymalnego.

brakuje jakiegoś zakończenia, podsumownaia, bo jest urwane w połowie